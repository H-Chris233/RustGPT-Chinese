# æ•™è‚²æ€§ä»£ç æŒ‡å— - RustGPT-Chinese

## ğŸ“ é¡¹ç›®æ•™è‚²ç›®æ ‡

æœ¬é¡¹ç›®çš„é¦–è¦ç›®æ ‡æ˜¯**æ•™å­¦**ï¼Œè€Œéç”Ÿäº§çº§æ€§èƒ½ã€‚æ¯ä¸€è¡Œä»£ç éƒ½åº”å½“ï¼š
- âœ… æ˜“äºç†è§£å’Œå­¦ä¹ 
- âœ… å±•ç¤ºæ ¸å¿ƒåŸç†å’Œç®—æ³•
- âœ… ä¿æŒæœ€å°ä¾èµ–ï¼Œä»é›¶å®ç°
- âœ… é€šè¿‡æ³¨é‡Šé˜æ˜è®¾è®¡å†³ç­–

---

## ğŸ“ æ³¨é‡ŠåŸåˆ™

### 1. å¿…é¡»æ³¨é‡Šçš„å†…å®¹

#### æ•°å­¦å…¬å¼å’Œç®—æ³•
```rust
/// è®¡ç®—ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ï¼ˆScaled Dot-Product Attentionï¼‰
///
/// # ç®—æ³•
/// ```
/// scores = (Q @ K^T) / sqrt(d_k)
/// attention = softmax(scores) @ V
/// ```
///
/// ç¼©æ”¾å› å­ sqrt(d_k) ç”¨äºé˜²æ­¢ softmax æ¢¯åº¦æ¶ˆå¤±
fn compute_attention(query: &Array2<f32>, key: &Array2<f32>, value: &Array2<f32>) -> Array2<f32> {
    // 1. è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
    let d_k = (key.ncols() as f32).sqrt();
    let scores = query.dot(&key.t()) / d_k;  // Q @ K^T / âˆšd_k
    
    // 2. Softmax å½’ä¸€åŒ–ï¼ˆæ•°å€¼ç¨³å®šæ€§å¤„ç†ï¼‰
    // å‡å»æœ€å¤§å€¼é˜²æ­¢ exp() æº¢å‡º
    let max_score = scores.fold(f32::NEG_INFINITY, |a, &b| a.max(b));
    let exp_scores = (scores - max_score).mapv(f32::exp);
    let sum_exp = exp_scores.sum_axis(Axis(1)).insert_axis(Axis(1));
    let attention_weights = &exp_scores / &sum_exp;
    
    // 3. åŠ æƒæ±‚å’Œ
    attention_weights.dot(value)
}
```

#### éæ˜¾è€Œæ˜“è§çš„ä¼˜åŒ–
```rust
// ä½¿ç”¨ KV-Cache é¿å…æ¨ç†æ—¶é‡å¤è®¡ç®—å†å² token çš„ Key å’Œ Value
// åŸç†ï¼šè‡ªå›å½’ç”Ÿæˆæ—¶ï¼Œæ¯æ¬¡åªéœ€è®¡ç®—æ–° token çš„æ³¨æ„åŠ›
if self.kv_cache_enabled {
    self.cached_keys.push(current_key);
    self.cached_values.push(current_value);
    
    // æ‹¼æ¥å†å²å’Œå½“å‰ Key/Value
    let all_keys = concatenate_cached(&self.cached_keys);
    let all_values = concatenate_cached(&self.cached_values);
}
```

#### å…³é”®è®¾è®¡å†³ç­–
```rust
// ä½¿ç”¨ Pre-LN æ¶æ„ï¼ˆLayerNorm åœ¨ Attention å‰ï¼‰
// ç†ç”±ï¼šè®­ç»ƒç¨³å®šæ€§æ›´å¥½ï¼Œæ”¶æ•›é€Ÿåº¦å¿« 20%ï¼ˆç›¸æ¯” Post-LNï¼‰
// å‚è€ƒ: GPT-2/3, BERT åæœŸæ¨¡å‹çš„æ ‡å‡†åšæ³•
let normalized = self.layer_norm.forward(input);
let attention_out = self.attention.forward(&normalized);
let residual = input + &attention_out;  // æ®‹å·®è¿æ¥
```

#### æ•°å€¼ç¨³å®šæ€§æŠ€å·§
```rust
// Softmax æ•°å€¼ç¨³å®šæ€§ï¼šå‡å»æœ€å¤§å€¼é˜²æ­¢ exp() æº¢å‡º
// æ•°å­¦ä¸Š: softmax(x - max(x)) = softmax(x)ï¼ˆæŒ‡æ•°å·®ä¸å˜ï¼‰
let max_val = logits.fold(f32::NEG_INFINITY, |a, &b| a.max(b));
let exp_logits = (logits - max_val).mapv(f32::exp);
let sum_exp = exp_logits.sum();
let probabilities = &exp_logits / sum_exp;
```

### 2. ä¸éœ€è¦æ³¨é‡Šçš„å†…å®¹

#### è‡ªè§£é‡Šçš„ä»£ç 
```rust
// âŒ ä¸å¥½ï¼šæ³¨é‡Šé‡å¤ä»£ç å†…å®¹
// è®¡ç®—åµŒå…¥ç»´åº¦
let embedding_dim = 256;

// âœ… å¥½ï¼šä»£ç å·²ç»å¾ˆæ¸…æ™°
let embedding_dim = 256;
```

#### æ˜¾è€Œæ˜“è§çš„æ“ä½œ
```rust
// âŒ ä¸å¥½
// è°ƒç”¨ forward æ–¹æ³•
let output = layer.forward(&input);

// âœ… å¥½ï¼šæ— éœ€æ³¨é‡Š
let output = layer.forward(&input);
```

### 3. æ³¨é‡Šé£æ ¼æŒ‡å—

#### å‡½æ•°æ–‡æ¡£æ³¨é‡Šï¼ˆä½¿ç”¨ Rust Doc æ ¼å¼ï¼‰
```rust
/// å¯¹è¾“å…¥å¼ é‡åº”ç”¨ GELU æ¿€æ´»å‡½æ•°
///
/// GELUï¼ˆGaussian Error Linear Unitï¼‰æ˜¯ä¸€ç§å¹³æ»‘çš„ ReLU å˜ä½“ï¼Œ
/// åœ¨ Transformer æ¨¡å‹ä¸­å¹¿æ³›ä½¿ç”¨ã€‚
///
/// # æ•°å­¦å®šä¹‰
/// ```
/// GELU(x) = x * Î¦(x)
/// å…¶ä¸­ Î¦(x) æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„ç´¯ç§¯åˆ†å¸ƒå‡½æ•°
/// ```
///
/// # è¿‘ä¼¼å®ç°
/// ä½¿ç”¨ tanh è¿‘ä¼¼:
/// ```
/// GELU(x) â‰ˆ 0.5 * x * (1 + tanh(âˆš(2/Ï€) * (x + 0.044715 * xÂ³)))
/// ```
///
/// # å‚æ•°
/// - `x`: è¾“å…¥å€¼
///
/// # è¿”å›
/// æ¿€æ´»åçš„å€¼
///
/// # ç¤ºä¾‹
/// ```
/// let activated = gelu(2.0);
/// assert!(activated > 1.9 && activated < 2.1);
/// ```
pub fn gelu(x: f32) -> f32 {
    const SQRT_2_OVER_PI: f32 = 0.7978845608;  // âˆš(2/Ï€)
    let inner = SQRT_2_OVER_PI * (x + 0.044715 * x.powi(3));
    0.5 * x * (1.0 + inner.tanh())
}
```

#### è¡Œå†…æ³¨é‡Šï¼ˆè§£é‡Š"ä¸ºä»€ä¹ˆ"è€Œé"æ˜¯ä»€ä¹ˆ"ï¼‰
```rust
// âœ… å¥½ï¼šè§£é‡ŠåŸå› 
// æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œé˜ˆå€¼ 5.0 æ˜¯ Transformer çš„ç»éªŒå€¼
if grad_norm > 5.0 {
    gradients = gradients * (5.0 / grad_norm);
}

// âŒ ä¸å¥½ï¼šé‡å¤ä»£ç 
// å¦‚æœæ¢¯åº¦èŒƒæ•°å¤§äº 5.0ï¼Œåˆ™è£å‰ªæ¢¯åº¦
if grad_norm > 5.0 {
    gradients = gradients * (5.0 / grad_norm);
}
```

---

## ğŸ—ï¸ ä»£ç ç»“æ„åŸåˆ™

### 1. å•ä¸€èŒè´£åŸåˆ™

æ¯ä¸ªæ–‡ä»¶/æ¨¡å—åªåšä¸€ä»¶äº‹ï¼š

```rust
// âœ… å¥½ï¼šå•ä¸€èŒè´£
// src/layer_norm.rs - åªå®ç° LayerNorm
pub struct LayerNorm { ... }
impl Layer for LayerNorm { ... }

// âŒ ä¸å¥½ï¼šå¤šä¸ªä¸ç›¸å…³åŠŸèƒ½
// src/utils.rs - æ··æ‚å„ç§åŠŸèƒ½
pub struct LayerNorm { ... }
pub struct Dropout { ... }
pub fn load_data() { ... }
```

### 2. æ˜¾å¼ä¼˜äºéšå¼

æ˜ç¡®å±•ç¤ºæ¯ä¸€æ­¥æ“ä½œï¼Œé¿å…"é­”æ³•"ï¼š

```rust
// âœ… å¥½ï¼šæ˜¾å¼çš„çŸ©é˜µä¹˜æ³•æ­¥éª¤
let query = input.dot(&self.w_q);  // X @ W_q
let key = input.dot(&self.w_k);    // X @ W_k
let value = input.dot(&self.w_v);  // X @ W_v

// âŒ ä¸å¥½ï¼šéšè—ç»†èŠ‚çš„é«˜çº§æŠ½è±¡
let qkv = self.qkv_projection(input);  // ä¸æ¸…æ¥šå†…éƒ¨åšäº†ä»€ä¹ˆ
```

### 3. æ•™è‚²å‹å¥½çš„å˜é‡å

ä½¿ç”¨æè¿°æ€§åç§°ï¼Œå³ä½¿è¾ƒé•¿ï¼š

```rust
// âœ… å¥½ï¼šæ¸…æ™°è¡¨è¾¾æ„å›¾
let attention_weights = softmax(&attention_scores);
let weighted_values = attention_weights.dot(&value_matrix);

// âŒ ä¸å¥½ï¼šæ•°å­¦ç¬¦å·ï¼ˆé™¤éåœ¨æ³¨é‡Šä¸­è§£é‡Šï¼‰
let a = softmax(&s);
let w = a.dot(&v);
```

### 4. åˆ†æ­¥éª¤å®ç°å¤æ‚ç®—æ³•

å°†å¤æ‚ç®—æ³•åˆ†è§£ä¸ºå¤šä¸ªæ¸…æ™°çš„æ­¥éª¤ï¼š

```rust
/// å¤šå¤´è‡ªæ³¨æ„åŠ›çš„å‰å‘ä¼ æ’­
///
/// åˆ†ä¸ºä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š
/// 1. çº¿æ€§æŠ•å½±ç”Ÿæˆ Q, K, V
/// 2. åˆ†å‰²å¤šå¤´å¹¶è®¡ç®—æ³¨æ„åŠ›
/// 3. æ‹¼æ¥å¤šå¤´å¹¶è¾“å‡ºæŠ•å½±
fn forward(&mut self, input: &Array2<f32>) -> Array2<f32> {
    // ========== æ­¥éª¤ 1: çº¿æ€§æŠ•å½± ==========
    let query = input.dot(&self.w_q);
    let key = input.dot(&self.w_k);
    let value = input.dot(&self.w_v);
    
    // ========== æ­¥éª¤ 2: å¤šå¤´æ³¨æ„åŠ› ==========
    let mut head_outputs = Vec::new();
    for head_idx in 0..self.num_heads {
        let q_head = self.split_head(&query, head_idx);
        let k_head = self.split_head(&key, head_idx);
        let v_head = self.split_head(&value, head_idx);
        
        let attention_out = self.compute_single_head_attention(q_head, k_head, v_head);
        head_outputs.push(attention_out);
    }
    
    // ========== æ­¥éª¤ 3: æ‹¼æ¥å’Œè¾“å‡ºæŠ•å½± ==========
    let concatenated = self.concatenate_heads(&head_outputs);
    concatenated.dot(&self.w_o)
}
```

---

## ğŸ§® æ•°å­¦å®ç°è§„èŒƒ

### 1. å…¬å¼æ³¨é‡Šæ ¼å¼

ä½¿ç”¨ Markdown ä»£ç å—æ ‡æ³¨æ•°å­¦å…¬å¼ï¼š

```rust
/// # ç®—æ³•ï¼šAdam ä¼˜åŒ–å™¨å‚æ•°æ›´æ–°
/// ```
/// m_t = Î²â‚ * m_{t-1} + (1 - Î²â‚) * g_t        // ä¸€é˜¶çŸ©ï¼ˆåŠ¨é‡ï¼‰
/// v_t = Î²â‚‚ * v_{t-1} + (1 - Î²â‚‚) * g_tÂ²       // äºŒé˜¶çŸ©ï¼ˆRMSPropï¼‰
/// mÌ‚_t = m_t / (1 - Î²â‚^t)                     // åå·®ä¿®æ­£
/// vÌ‚_t = v_t / (1 - Î²â‚‚^t)
/// Î¸_t = Î¸_{t-1} - Î± * mÌ‚_t / (âˆšvÌ‚_t + Îµ)      // å‚æ•°æ›´æ–°
/// ```
```

### 2. å˜é‡ä¸å…¬å¼å¯¹åº”

ä»£ç å˜é‡åä¸æ•°å­¦ç¬¦å·å¯¹åº”æ¸…æ™°ï¼š

```rust
// è®ºæ–‡å…¬å¼: Attention(Q, K, V) = softmax(Q K^T / âˆšd_k) V
fn scaled_dot_product_attention(
    query: &Array2<f32>,   // Q
    key: &Array2<f32>,     // K
    value: &Array2<f32>,   // V
    d_k: f32,              // é”®çš„ç»´åº¦
) -> Array2<f32> {
    // QK^T
    let scores = query.dot(&key.t());
    
    // QK^T / âˆšd_k
    let scaled_scores = scores / d_k.sqrt();
    
    // softmax(QK^T / âˆšd_k)
    let attention_weights = softmax(&scaled_scores);
    
    // softmax(...) V
    attention_weights.dot(value)
}
```

### 3. æ¢¯åº¦æ¨å¯¼æ³¨é‡Š

åå‘ä¼ æ’­å¿…é¡»æ³¨é‡Šæ¢¯åº¦æ¨å¯¼ï¼š

```rust
/// # åå‘ä¼ æ’­ï¼šLayerNorm æ¢¯åº¦æ¨å¯¼
///
/// ## å‰å‘å…¬å¼
/// ```
/// Î¼ = mean(x)
/// ÏƒÂ² = var(x)
/// xÌ‚ = (x - Î¼) / âˆš(ÏƒÂ² + Îµ)
/// y = Î³ * xÌ‚ + Î²
/// ```
///
/// ## åå‘æ¢¯åº¦ï¼ˆé“¾å¼æ³•åˆ™ï¼‰
/// ```
/// âˆ‚L/âˆ‚Î³ = Î£ (âˆ‚L/âˆ‚y * xÌ‚)
/// âˆ‚L/âˆ‚Î² = Î£ (âˆ‚L/âˆ‚y)
/// âˆ‚L/âˆ‚x = (âˆ‚L/âˆ‚y * Î³ / âˆš(ÏƒÂ² + Îµ)) * (1 - 1/N - (xÌ‚)Â² / N)
/// ```
fn backward(&mut self, grad_output: &Array2<f32>, lr: f32) -> Array2<f32> {
    // 1. è®¡ç®— âˆ‚L/âˆ‚Î³ å’Œ âˆ‚L/âˆ‚Î²
    let grad_gamma = (grad_output * &self.normalized_input).sum_axis(Axis(0));
    let grad_beta = grad_output.sum_axis(Axis(0));
    
    // 2. è®¡ç®— âˆ‚L/âˆ‚xÌ‚
    let grad_normalized = grad_output * &self.gamma.view().insert_axis(Axis(0));
    
    // 3. è®¡ç®— âˆ‚L/âˆ‚xï¼ˆåå‘ä¼ æ’­é€šè¿‡å½’ä¸€åŒ–ï¼‰
    let grad_input = self.compute_input_gradient(&grad_normalized);
    
    // 4. æ›´æ–°å‚æ•°
    self.gamma = &self.gamma - lr * &grad_gamma;
    self.beta = &self.beta - lr * &grad_beta;
    
    grad_input
}
```

---

## ğŸ§ª æµ‹è¯•è§„èŒƒ

### 1. æµ‹è¯•é©±åŠ¨çš„æ•™å­¦

æ¯ä¸ªåŠŸèƒ½å¿…é¡»æœ‰å¯¹åº”æµ‹è¯•ï¼š

```rust
#[cfg(test)]
mod tests {
    use super::*;

    /// æµ‹è¯•ï¼šéªŒè¯ GELU æ¿€æ´»å‡½æ•°åœ¨ x=0 æ—¶çš„å€¼
    /// é¢„æœŸ: GELU(0) = 0
    #[test]
    fn test_gelu_at_zero() {
        let result = gelu(0.0);
        assert_eq!(result, 0.0, "GELU(0) åº”è¯¥ç­‰äº 0");
    }

    /// æµ‹è¯•ï¼šéªŒè¯ GELU çš„å¹³æ»‘æ€§è´¨
    /// GELU åº”è¯¥åœ¨è´Ÿæ•°åŒºåŸŸæœ‰å°çš„æ¢¯åº¦ï¼ˆä¸åƒ ReLU ç›´æ¥æˆªæ–­ä¸º 0ï¼‰
    #[test]
    fn test_gelu_smoothness() {
        let negative_result = gelu(-1.0);
        assert!(
            negative_result < 0.0 && negative_result > -1.0,
            "GELU åº”è¯¥åœ¨è´Ÿæ•°åŒºåŸŸæœ‰éé›¶è¾“å‡ºï¼Œä½“ç°å¹³æ»‘æ€§"
        );
    }

    /// æµ‹è¯•ï¼šéªŒè¯æ­£æ•°åŒºåŸŸæ¥è¿‘çº¿æ€§
    /// å½“ x è¾ƒå¤§æ—¶ï¼ŒGELU(x) â‰ˆ x
    #[test]
    fn test_gelu_linearity_at_large_values() {
        let x = 3.0;
        let result = gelu(x);
        assert!(
            (result - x).abs() < 0.1,
            "GELU åœ¨å¤§æ­£æ•°æ—¶åº”æ¥è¿‘ x"
        );
    }
}
```

### 2. æµ‹è¯•ä½œä¸ºæ–‡æ¡£

æµ‹è¯•ç”¨ä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ¨¡å—ï¼š

```rust
/// ç¤ºä¾‹ï¼šå¦‚ä½•ä½¿ç”¨ Vocab æ„å»ºè¯æ±‡è¡¨å¹¶ç¼–ç æ–‡æœ¬
#[test]
fn test_vocab_usage_example() {
    // 1. å‡†å¤‡è®­ç»ƒæ–‡æœ¬
    let texts = vec![
        "æ·±åº¦å­¦ä¹ å¾ˆæœ‰è¶£".to_string(),
        "Transformer æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œ".to_string(),
    ];
    
    // 2. æ„å»ºè¯æ±‡è¡¨ï¼ˆè‡ªåŠ¨ä½¿ç”¨ Jieba åˆ†è¯ï¼‰
    let vocab = Vocab::build_from_texts(&texts);
    
    // 3. ç¼–ç æ–‡æœ¬ä¸º token IDs
    let text = "æ·±åº¦å­¦ä¹ ";
    let token_ids = vocab.encode_sequence(text);
    
    // 4. è§£ç  token IDs å›æ–‡æœ¬
    let decoded = vocab.decode_sequence(&token_ids);
    
    assert!(decoded.contains("æ·±åº¦"));
    assert!(decoded.contains("å­¦ä¹ "));
}
```

### 3. è¾¹ç•Œæµ‹è¯•ï¼ˆæ•™å­¦ä»·å€¼é«˜ï¼‰

æµ‹è¯•è¾¹ç•Œæƒ…å†µå¸®åŠ©ç†è§£ç®—æ³•é™åˆ¶ï¼š

```rust
/// æµ‹è¯•ï¼šç©ºè¾“å…¥
#[test]
fn test_forward_with_empty_input() {
    let layer = FeedForward::new(256, 512);
    let empty_input = Array2::zeros((0, 256));
    let output = layer.forward(&empty_input);
    assert_eq!(output.shape(), &[0, 256]);
}

/// æµ‹è¯•ï¼šè¶…é•¿åºåˆ—æˆªæ–­
#[test]
fn test_context_truncation_at_max_length() {
    let mut model = LLM::new(vocab);
    
    // æ·»åŠ è¶…è¿‡ MAX_SEQ_LEN çš„ token
    for _ in 0..200 {
        model.context.push(1);  // æ·»åŠ  200 ä¸ª token
    }
    
    // åº”è¯¥åªä¿ç•™æœ€è¿‘çš„ 128 ä¸ªï¼ˆMAX_SEQ_LENï¼‰
    assert_eq!(model.context.len(), 128);
}
```

---

## ğŸ“š ä¾èµ–ç®¡ç†å“²å­¦

### åªæ·»åŠ æ— æ³•ç®€å•å®ç°çš„ä¾èµ–

#### âœ… å¯æ¥å—çš„ä¾èµ–
```rust
// ndarray - å¼ é‡è®¡ç®—æ˜¯æ ¸å¿ƒï¼Œæ‰‹å†™æ•ˆç‡ä½ä¸”æ˜“é”™
use ndarray::{Array2, Axis};

// jieba-rs - ä¸­æ–‡åˆ†è¯æ˜¯ä¸“é—¨é¢†åŸŸï¼Œéœ€è¦è¯å…¸å’Œç»Ÿè®¡æ¨¡å‹
use jieba_rs::Jieba;

// serde - åºåˆ—åŒ–æ˜¯é€šç”¨éœ€æ±‚ï¼Œæ ‡å‡†åº“æœªæä¾›
use serde::{Serialize, Deserialize};
```

#### âŒ åº”é¿å…çš„ä¾èµ–
```rust
// PyTorch ç»‘å®š - éšè—å®ç°ç»†èŠ‚ï¼Œè¿èƒŒæ•™å­¦ç›®æ ‡
// use tch::{Tensor, nn};  âŒ

// è‡ªåŠ¨å¾®åˆ†åº“ - æ‰‹å†™æ¢¯åº¦æœ‰æ•™å­¦ä»·å€¼
// use autograd::{grad, backward};  âŒ

// CSV è§£æ - ç®€å•æ ¼å¼å¯è‡ªå·±å®ç°
// use csv::Reader;  âŒ
```

### æœ€å°åŒ–ä¾èµ–åŸåˆ™

```toml
# âœ… å¥½ï¼šåªä¾èµ–å¿…éœ€çš„æ ¸å¿ƒåŠŸèƒ½
[dependencies]
ndarray = "0.16"
jieba-rs = "0.7"

# âŒ ä¸å¥½ï¼šæ·»åŠ "å¯èƒ½æœ‰ç”¨"çš„ä¾èµ–
[dependencies]
ndarray = "0.16"
jieba-rs = "0.7"
tokio = "1.0"       # å¼‚æ­¥è¿è¡Œæ—¶ï¼ˆæœ¬é¡¹ç›®ä¸éœ€è¦ï¼‰
reqwest = "0.11"    # HTTP å®¢æˆ·ç«¯ï¼ˆæœ¬é¡¹ç›®ä¸éœ€è¦ï¼‰
clap = "4.0"        # å‘½ä»¤è¡Œè§£æï¼ˆå½“å‰ç®€å•äº¤äº’è¶³å¤Ÿï¼‰
```

---

## ğŸ¨ ä»£ç ç¾å­¦

### 1. å¯¹é½å’Œæ ¼å¼

ä½¿ç”¨ä¸€è‡´çš„å¯¹é½æé«˜å¯è¯»æ€§ï¼š

```rust
// âœ… å¥½ï¼šå¯¹é½çš„ç»“æ„ä½“å­—æ®µ
pub struct TransformerConfig {
    pub max_seq_len:    usize,  // 128
    pub embedding_dim:  usize,  // 256
    pub hidden_dim:     usize,  // 512
    pub num_heads:      usize,  // 8
    pub num_layers:     usize,  // 2
    pub dropout_rate:   f32,    // 0.1
}

// âœ… å¥½ï¼šå¯¹é½çš„å‚æ•°èµ‹å€¼
let config = TransformerConfig {
    max_seq_len:    128,
    embedding_dim:  256,
    hidden_dim:     512,
    num_heads:      8,
    num_layers:     2,
    dropout_rate:   0.1,
};
```

### 2. åˆ†éš”å¤æ‚é€»è¾‘

ä½¿ç”¨ç©ºè¡Œå’Œæ³¨é‡Šåˆ†éš”é€»è¾‘å—ï¼š

```rust
fn train_epoch(&mut self, dataset: &[String], lr: f32) {
    // ========== é˜¶æ®µ 1: æ•°æ®é¢„å¤„ç† ==========
    let tokenized_data = self.preprocess_dataset(dataset);
    let total_samples = tokenized_data.len();
    
    println!("å¼€å§‹è®­ç»ƒï¼Œå…± {} ä¸ªæ ·æœ¬", total_samples);
    
    // ========== é˜¶æ®µ 2: å‰å‘ä¼ æ’­å’ŒæŸå¤±è®¡ç®— ==========
    let mut total_loss = 0.0;
    for sample in &tokenized_data {
        let output = self.forward(sample, true);  // training=true
        let loss = self.compute_loss(&output, sample);
        total_loss += loss;
    }
    
    // ========== é˜¶æ®µ 3: åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–° ==========
    let avg_loss = total_loss / total_samples as f32;
    self.backward(&loss_gradient, lr);
    
    // ========== é˜¶æ®µ 4: æŒ‡æ ‡è®°å½• ==========
    self.metrics.push(avg_loss);
    println!("Epoch å®Œæˆï¼Œå¹³å‡ Loss: {:.4}", avg_loss);
}
```

### 3. ä¸€è‡´çš„å‘½åé£æ ¼

```rust
// âœ… å¥½ï¼šä¸€è‡´çš„å‘½åæ¨¡å¼
pub struct Embeddings { ... }      // åè¯ï¼Œå¤æ•°
pub struct LayerNorm { ... }       // åè¯ç»„åˆ
pub struct SelfAttention { ... }   // åè¯ç»„åˆ

fn forward(&mut self, ...) { ... }      // åŠ¨è¯
fn compute_loss(...) { ... }            // åŠ¨è¯ + åè¯
fn build_vocabulary(...) { ... }        // åŠ¨è¯ + åè¯

// âŒ ä¸å¥½ï¼šæ··ä¹±çš„å‘½å
pub struct Embed { ... }           // åŠ¨è¯å½¢å¼
pub struct NormLayer { ... }       // é¡ºåºä¸ä¸€è‡´

fn go_forward(...) { ... }         // å†—ä½™çš„ "go"
fn loss_computation(...) { ... }   // åè¯å½¢å¼
```

---

## ğŸš« åæ¨¡å¼ï¼ˆåº”é¿å…ï¼‰

### 1. è¿‡åº¦æŠ½è±¡

```rust
// âŒ ä¸å¥½ï¼šä¸ºäº†æŠ½è±¡è€ŒæŠ½è±¡ï¼ˆå¢åŠ ç†è§£éš¾åº¦ï¼‰
trait Computable {
    fn compute(&self) -> Box<dyn Any>;
}

struct Layer {
    operation: Box<dyn Computable>,
}

// âœ… å¥½ï¼šç›´æ¥å®ç°ï¼ˆæ¸…æ™°æ˜“æ‡‚ï¼‰
pub struct FeedForward {
    w1: Array2<f32>,
    b1: Array1<f32>,
}

impl FeedForward {
    pub fn forward(&self, input: &Array2<f32>) -> Array2<f32> {
        // ç›´æ¥çš„çŸ©é˜µè¿ç®—
        input.dot(&self.w1) + &self.b1
    }
}
```

### 2. éšè—çš„é­”æ³•æ•°å­—

```rust
// âŒ ä¸å¥½ï¼šæ²¡æœ‰è§£é‡Šçš„é­”æ³•æ•°å­—
let output = input * 0.044715;

// âœ… å¥½ï¼šå¸¸é‡ + æ³¨é‡Šè¯´æ˜
const GELU_CUBIC_COEFF: f32 = 0.044715;  // GELU æ¿€æ´»å‡½æ•°çš„ä¸‰æ¬¡é¡¹ç³»æ•°
let output = input * GELU_CUBIC_COEFF;
```

### 3. è¿‡åº¦ä½¿ç”¨å®

```rust
// âŒ ä¸å¥½ï¼šå¤æ‚çš„å®éšè—é€»è¾‘
macro_rules! define_layer {
    ($name:ident, $dim:expr) => {
        // å¤æ‚çš„å®å±•å¼€é€»è¾‘...
    };
}

// âœ… å¥½ï¼šæ˜¾å¼çš„ç»“æ„ä½“å®šä¹‰
pub struct FeedForward {
    input_dim: usize,
    hidden_dim: usize,
}

impl FeedForward {
    pub fn new(input_dim: usize, hidden_dim: usize) -> Self { ... }
}
```

### 4. è¿‡åº¦ä¼˜åŒ–ï¼ˆä»¥ç‰ºç‰²å¯è¯»æ€§ä¸ºä»£ä»·ï¼‰

```rust
// âŒ ä¸å¥½ï¼šè¿‡åº¦ä¼˜åŒ–å¯¼è‡´éš¾ä»¥ç†è§£
let result = input
    .axis_iter(Axis(0))
    .zip(weights.axis_iter(Axis(1)))
    .flat_map(|(i, w)| i.iter().zip(w.iter()))
    .map(|(x, w)| x * w)
    .sum::<f32>();

// âœ… å¥½ï¼šæ¸…æ™°çš„çŸ©é˜µä¹˜æ³•ï¼ˆndarray å†…éƒ¨å·²ä¼˜åŒ–ï¼‰
let result = input.dot(&weights);
```

---

## ğŸ“– å­¦ä¹ è·¯å¾„å»ºè®®

### æ–°æ‰‹å…¥é—¨é¡ºåº

å¯¹äºæƒ³è¦å­¦ä¹ æœ¬é¡¹ç›®çš„å¼€å‘è€…ï¼Œå»ºè®®æŒ‰ä»¥ä¸‹é¡ºåºé˜…è¯»ä»£ç ï¼š

1. **lib.rs** - ç†è§£å…¨å±€é…ç½®å’Œ Layer trait
2. **main.rs** - ç†è§£æ•´ä½“è®­ç»ƒæµç¨‹
3. **vocab.rs** - ç†è§£ä¸­æ–‡åˆ†è¯å’Œè¯æ±‡è¡¨
4. **embeddings.rs** - ç¬¬ä¸€ä¸ªç®€å•çš„å±‚
5. **layer_norm.rs** - ç†è§£å½’ä¸€åŒ–
6. **feed_forward.rs** - ç†è§£å‰é¦ˆç½‘ç»œ
7. **self_attention.rs** - ç†è§£æ³¨æ„åŠ›æœºåˆ¶ï¼ˆæ ¸å¿ƒï¼‰
8. **transformer.rs** - ç†è§£å±‚çš„ç»„åˆ
9. **llm.rs** - ç†è§£å‰å‘/åå‘ä¼ æ’­
10. **tests/** - é€šè¿‡æµ‹è¯•ç†è§£æ¯ä¸ªæ¨¡å—

### è¿›é˜¶å­¦ä¹ å»ºè®®

#### ä¿®æ”¹å®éªŒ
1. **è°ƒæ•´è¶…å‚æ•°**: ä¿®æ”¹ `lib.rs` ä¸­çš„é…ç½®ï¼Œè§‚å¯Ÿæ•ˆæœ
2. **æ›´æ¢æ¿€æ´»å‡½æ•°**: å°† GELU æ›¿æ¢ä¸º ReLUï¼Œå¯¹æ¯”æ”¶æ•›é€Ÿåº¦
3. **æ·»åŠ æ–°å±‚**: å®ç° Batch Normalization æˆ– Group Normalization
4. **æ”¹è¿›é‡‡æ ·**: å®ç° Temperature Annealing æˆ– Contrastive Search

#### æ·±å…¥ç†è§£
1. **æ‰‹åŠ¨æ¨å¯¼æ¢¯åº¦**: å¯¹æ¯”ä»£ç ä¸­çš„åå‘ä¼ æ’­å®ç°
2. **å¯è§†åŒ–æ³¨æ„åŠ›**: è¾“å‡ºæ³¨æ„åŠ›æƒé‡çŸ©é˜µå¹¶å¯è§†åŒ–
3. **åˆ†ææ€§èƒ½**: ä½¿ç”¨ `cargo flamegraph` æ‰¾å‡ºæ€§èƒ½ç“¶é¢ˆ
4. **é˜…è¯»è®ºæ–‡**: å¯¹ç…§ "Attention Is All You Need" è®ºæ–‡

---

## ğŸ¯ ä»£ç å®¡æŸ¥ Checklistï¼ˆæ•™è‚²è§†è§’ï¼‰

### æäº¤ä»£ç å‰è‡ªæŸ¥

- [ ] **æ³¨é‡Šå……åˆ†**: å¤æ‚ç®—æ³•æœ‰å…¬å¼å’Œæ¨å¯¼è¯´æ˜
- [ ] **å˜é‡å‘½å**: æè¿°æ€§åç§°ï¼Œé¿å…å•å­—æ¯ï¼ˆé™¤æ•°å­¦æƒ¯ä¾‹ï¼‰
- [ ] **é€»è¾‘åˆ†æ­¥**: å¤æ‚å‡½æ•°åˆ†è§£ä¸ºå¤šä¸ªæ¸…æ™°æ­¥éª¤
- [ ] **æµ‹è¯•å®Œæ•´**: è‡³å°‘æœ‰åŸºæœ¬çš„åŠŸèƒ½æµ‹è¯•
- [ ] **æ–‡æ¡£æ›´æ–°**: æ–°åŠŸèƒ½æ›´æ–°äº† CLAUDE.md æˆ– README
- [ ] **æœ€å°ä¾èµ–**: æ²¡æœ‰å¼•å…¥ä¸å¿…è¦çš„ä¾èµ–
- [ ] **æ—  unsafe**: æ²¡æœ‰ä½¿ç”¨ unsafe ä»£ç ï¼ˆé™¤ä¾èµ–åº“å†…éƒ¨ï¼‰
- [ ] **æ— é­”æ³•æ•°å­—**: å¸¸é‡æœ‰æ¸…æ™°å‘½åå’Œæ³¨é‡Š
- [ ] **æ ¼å¼è§„èŒƒ**: é€šè¿‡ `cargo fmt` æ£€æŸ¥
- [ ] **æ— è­¦å‘Š**: é€šè¿‡ `cargo clippy` æ£€æŸ¥

### ä»£ç å®¡æŸ¥é—®é¢˜æ¸…å•

å®¡æŸ¥ä»–äººä»£ç æ—¶åº”é—®ï¼š

1. **æ•™è‚²ä»·å€¼**: è¿™æ®µä»£ç æ˜¯å¦å¸®åŠ©å­¦ä¹ è€…ç†è§£ç®—æ³•åŸç†ï¼Ÿ
2. **å¯è¯»æ€§**: æ²¡æœ‰ç›¸å…³çŸ¥è¯†çš„äººèƒ½å¦é€šè¿‡æ³¨é‡Šç†è§£ï¼Ÿ
3. **å¿…è¦æ€§**: è¿™ä¸ªåŠŸèƒ½/ä¾èµ–æ˜¯å¦å¿…éœ€ï¼Ÿ
4. **ç®€æ´æ€§**: èƒ½å¦ç”¨æ›´ç®€å•çš„æ–¹å¼å®ç°ï¼Ÿ
5. **æµ‹è¯•æ€§**: æ˜¯å¦æœ‰æµ‹è¯•ç”¨ä¾‹éªŒè¯åŠŸèƒ½ï¼Ÿ

---

## ğŸ’¡ ç¤ºä¾‹ï¼šæ•™è‚²å‹å¥½çš„ä»£ç 

### å®Œæ•´ç¤ºä¾‹ï¼šå®ç°ä¸€ä¸ªæ–°å±‚

```rust
//! # Dropout æ­£åˆ™åŒ–å±‚
//!
//! Dropout æ˜¯ä¸€ç§é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œé€šè¿‡åœ¨è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒéƒ¨åˆ†ç¥ç»å…ƒã€‚
//!
//! ## åŸç†
//! - **è®­ç»ƒæ—¶**: ä»¥æ¦‚ç‡ p éšæœºå°†ç¥ç»å…ƒè¾“å‡ºç½®ä¸º 0
//! - **æ¨ç†æ—¶**: ä¸ä¸¢å¼ƒï¼Œä½†è¾“å‡ºç¼©æ”¾ä¸º (1 - p) å€
//!
//! ## ä¸ºä»€ä¹ˆæœ‰æ•ˆ
//! è¿«ä½¿ç½‘ç»œä¸ä¾èµ–ç‰¹å®šç¥ç»å…ƒï¼Œå­¦ä¹ æ›´é²æ£’çš„ç‰¹å¾ã€‚
//!
//! ## å‚è€ƒ
//! - è®ºæ–‡: "Dropout: A Simple Way to Prevent Neural Networks from Overfitting" (Srivastava et al., 2014)

use ndarray::Array2;
use rand::Rng;

use crate::Layer;

/// Dropout å±‚ç»“æ„ä½“
///
/// # å­—æ®µ
/// - `dropout_rate`: ä¸¢å¼ƒæ¦‚ç‡ï¼ˆé€šå¸¸ 0.1 ~ 0.5ï¼‰
/// - `training`: è®­ç»ƒæ¨¡å¼å¼€å…³
/// - `mask`: ç¼“å­˜çš„ Dropout æ©ç ï¼ˆåå‘ä¼ æ’­éœ€è¦ï¼‰
pub struct Dropout {
    dropout_rate: f32,
    training: bool,
    mask: Option<Array2<f32>>,
}

impl Dropout {
    /// åˆ›å»ºæ–°çš„ Dropout å±‚
    ///
    /// # å‚æ•°
    /// - `dropout_rate`: ä¸¢å¼ƒæ¦‚ç‡ï¼ˆ0.0 ~ 1.0ï¼‰
    ///
    /// # ç¤ºä¾‹
    /// ```
    /// let dropout = Dropout::new(0.1);  // 10% çš„ç¥ç»å…ƒè¢«ä¸¢å¼ƒ
    /// ```
    pub fn new(dropout_rate: f32) -> Self {
        assert!(
            dropout_rate >= 0.0 && dropout_rate < 1.0,
            "Dropout rate å¿…é¡»åœ¨ [0, 1) èŒƒå›´å†…"
        );
        
        Self {
            dropout_rate,
            training: true,
            mask: None,
        }
    }
}

impl Layer for Dropout {
    fn layer_type(&self) -> &str {
        "Dropout"
    }
    
    fn forward(&mut self, input: &Array2<f32>) -> Array2<f32> {
        if !self.training {
            // æ¨ç†æ¨¡å¼ï¼šç›´æ¥è¿”å›è¾“å…¥
            return input.clone();
        }
        
        // ========== è®­ç»ƒæ¨¡å¼ï¼šåº”ç”¨ Dropout ==========
        
        // 1. ç”Ÿæˆéšæœºæ©ç ï¼š0 æˆ– 1
        //    å¦‚æœ rand() > dropout_rateï¼Œåˆ™ä¿ç•™ï¼ˆmask = 1ï¼‰
        //    å¦åˆ™ä¸¢å¼ƒï¼ˆmask = 0ï¼‰
        let mut rng = rand::thread_rng();
        let mask = input.mapv(|_| {
            if rng.gen::<f32>() > self.dropout_rate {
                1.0
            } else {
                0.0
            }
        });
        
        // 2. åº”ç”¨æ©ç å¹¶ç¼©æ”¾
        //    ç¼©æ”¾å› å­: 1 / (1 - p)
        //    åŸå› ï¼šä¿æŒæœŸæœ›å€¼ä¸å˜ï¼ˆE[output] = E[input]ï¼‰
        let keep_prob = 1.0 - self.dropout_rate;
        let output = (input * &mask) / keep_prob;
        
        // 3. ç¼“å­˜æ©ç ï¼ˆåå‘ä¼ æ’­éœ€è¦ï¼‰
        self.mask = Some(mask);
        
        output
    }
    
    fn backward(&mut self, grad_output: &Array2<f32>, _lr: f32) -> Array2<f32> {
        // Dropout æ²¡æœ‰å¯å­¦ä¹ å‚æ•°ï¼Œç›´æ¥ä¼ é€’æ¢¯åº¦
        
        if !self.training {
            // æ¨ç†æ¨¡å¼ï¼šç›´æ¥ä¼ é€’æ¢¯åº¦
            return grad_output.clone();
        }
        
        // è®­ç»ƒæ¨¡å¼ï¼šåº”ç”¨ç›¸åŒçš„æ©ç å’Œç¼©æ”¾
        let mask = self.mask.as_ref().expect("Forward å¿…é¡»å…ˆäº Backward è°ƒç”¨");
        let keep_prob = 1.0 - self.dropout_rate;
        
        (grad_output * mask) / keep_prob
    }
    
    fn parameters(&self) -> usize {
        0  // Dropout æ²¡æœ‰å¯å­¦ä¹ å‚æ•°
    }
    
    fn set_training_mode(&mut self, training: bool) {
        self.training = training;
    }
}

// ========== å•å…ƒæµ‹è¯• ==========

#[cfg(test)]
mod tests {
    use super::*;
    use ndarray::Array;

    /// æµ‹è¯•ï¼šæ¨ç†æ¨¡å¼ä¸åº”ä¿®æ”¹è¾“å…¥
    #[test]
    fn test_inference_mode_no_dropout() {
        let mut dropout = Dropout::new(0.5);
        dropout.set_training_mode(false);  // æ¨ç†æ¨¡å¼
        
        let input = Array::from_shape_vec((2, 3), vec![1.0; 6]).unwrap();
        let output = dropout.forward(&input);
        
        assert_eq!(input, output, "æ¨ç†æ¨¡å¼ä¸åº”ä¿®æ”¹è¾“å…¥");
    }

    /// æµ‹è¯•ï¼šè®­ç»ƒæ¨¡å¼åº”æœ‰éƒ¨åˆ†å…ƒç´ ä¸º 0
    #[test]
    fn test_training_mode_drops_elements() {
        let mut dropout = Dropout::new(0.5);
        dropout.set_training_mode(true);  // è®­ç»ƒæ¨¡å¼
        
        let input = Array::from_shape_vec((100, 100), vec![1.0; 10000]).unwrap();
        let output = dropout.forward(&input);
        
        // ç»Ÿè®¡ä¸º 0 çš„å…ƒç´ æ•°é‡
        let zero_count = output.iter().filter(|&&x| x == 0.0).count();
        
        // 50% dropout åº”è¯¥æœ‰çº¦ä¸€åŠå…ƒç´ ä¸º 0ï¼ˆå…è®¸ 10% è¯¯å·®ï¼‰
        let expected = 5000;
        let tolerance = 500;
        assert!(
            (zero_count as i32 - expected).abs() < tolerance,
            "Dropout åº”ä¸¢å¼ƒçº¦ 50% çš„å…ƒç´ ï¼Œå®é™…ä¸¢å¼ƒ {}%",
            zero_count as f32 / 10000.0 * 100.0
        );
    }

    /// æµ‹è¯•ï¼šæœŸæœ›å€¼ä¿æŒä¸å˜
    #[test]
    fn test_expectation_invariance() {
        let mut dropout = Dropout::new(0.3);
        dropout.set_training_mode(true);
        
        let input = Array::from_shape_vec((1000, 100), vec![2.0; 100000]).unwrap();
        let output = dropout.forward(&input);
        
        // è®¡ç®—å¹³å‡å€¼ï¼ˆåº”è¯¥æ¥è¿‘ 2.0ï¼‰
        let mean = output.mean().unwrap();
        assert!(
            (mean - 2.0).abs() < 0.1,
            "Dropout åº”ä¿æŒæœŸæœ›å€¼ä¸å˜ï¼Œè¾“å…¥å‡å€¼ 2.0ï¼Œè¾“å‡ºå‡å€¼ {}",
            mean
        );
    }
}
```

---

*æœ¬æŒ‡å—æœ€åæ›´æ–°: 2024-10-25 | ç‰ˆæœ¬: v0.4.0*
